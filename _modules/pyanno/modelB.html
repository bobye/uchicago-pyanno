

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>pyanno.modelB &mdash; pyanno 2.0 documentation</title>
    
    <link rel="stylesheet" href="../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '2.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="top" title="pyanno 2.0 documentation" href="../../index.html" />
    <link rel="up" title="Module code" href="../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">pyanno 2.0 documentation</a> &raquo;</li>
          <li><a href="../index.html" accesskey="U">Module code</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <h1>Source code for pyanno.modelB</h1><div class="highlight"><pre>
<span class="c"># Copyright (c) 2011, Enthought, Ltd.</span>
<span class="c"># Authors: Pietro Berkes &lt;pberkes@enthought.com&gt;, Bob Carpenter</span>
<span class="c"># License: Modified BSD license (2-clause)</span>

<span class="sd">&quot;&quot;&quot;This module defines the class ModelB, a Bayesian generalization</span>
<span class="sd">of the model proposed in (Dawid et al., 1979).</span>

<span class="sd">**Reference:**</span>

<span class="sd">* Dawid, A. P. and A. M. Skene. 1979.  Maximum likelihood</span>
<span class="sd">  estimation of observer error-rates using the EM algorithm.  Applied</span>
<span class="sd">  Statistics, 28(1):20--28.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">traits.api</span> <span class="kn">import</span> <span class="n">Int</span><span class="p">,</span> <span class="n">Array</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">pyanno.abstract_model</span> <span class="kn">import</span> <span class="n">AbstractModel</span>
<span class="kn">from</span> <span class="nn">pyanno.util</span> <span class="kn">import</span> <span class="p">(</span><span class="n">random_categorical</span><span class="p">,</span> <span class="n">create_band_matrix</span><span class="p">,</span>
                         <span class="n">normalize</span><span class="p">,</span> <span class="n">dirichlet_llhood</span><span class="p">,</span>
                         <span class="n">is_valid</span><span class="p">,</span> <span class="n">SMALLEST_FLOAT</span><span class="p">,</span> <span class="n">PyannoValueError</span><span class="p">,</span> <span class="n">labels_count</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>

<span class="n">ALPHA_DEFAULT</span> <span class="o">=</span> <span class="p">[</span><span class="mf">16.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]</span>


<div class="viewcode-block" id="ModelB"><a class="viewcode-back" href="../../pyanno.models.html#pyanno.modelB.ModelB">[docs]</a><span class="k">class</span> <span class="nc">ModelB</span><span class="p">(</span><span class="n">AbstractModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Bayesian generalization of the model proposed in (Dawid et al., 1979).</span>

<span class="sd">    Model B is a hierarchical generative model over annotations. The model</span>
<span class="sd">    assumes the existence of &quot;true&quot; underlying labels for each item,</span>
<span class="sd">    which are drawn from a categorical distribution,</span>
<span class="sd">    :math:`\pi`. Annotators report this labels with some noise, depending</span>
<span class="sd">    on their accuracy, :math:`\\theta`.</span>

<span class="sd">    The model parameters are:</span>

<span class="sd">        - `pi[k]` is the probability of label k</span>

<span class="sd">        - `theta[j,k,k&#39;]` is the probability that annotator j reports label k&#39;</span>
<span class="sd">          for an item whose real label is k, i.e.</span>
<span class="sd">          P( annotator j chooses k&#39; | real label = k)</span>

<span class="sd">    The parameters themselves are random variables with hyperparameters</span>

<span class="sd">        - `beta` are the parameters of a Dirichlet distribution over `pi`</span>

<span class="sd">        - `alpha[k,:]` are the parameters of Dirichlet distributions over</span>
<span class="sd">          `theta[j,k,:]`</span>

<span class="sd">    See the documentation for a more detailed description of the model.</span>

<span class="sd">    **References:**</span>

<span class="sd">    * Dawid, A. P. and A. M. Skene. 1979.  Maximum likelihood</span>
<span class="sd">      estimation of observer error-rates using the EM algorithm.  Applied</span>
<span class="sd">      Statistics, 28(1):20--28.</span>

<span class="sd">    * Rzhetsky A., Shatkay, H., and Wilbur, W.J. (2009). &quot;How to get the most</span>
<span class="sd">      from your curation effort&quot;, PLoS Computational Biology, 5(5).</span>
<span class="sd">    &quot;&quot;&quot;</span>


    <span class="c">######## Model traits</span>

    <span class="c"># number of label classes</span>
    <span class="n">nclasses</span> <span class="o">=</span> <span class="n">Int</span>

    <span class="c"># number of annotators</span>
    <span class="n">nannotators</span> <span class="o">=</span> <span class="n">Int</span>

    <span class="c">#### Model parameters</span>

    <span class="c"># pi[k] is the prior probability of class k</span>
    <span class="n">pi</span> <span class="o">=</span> <span class="n">Array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,))</span>

    <span class="c"># theta[j,k,:] is P(annotator j chooses : | real label = k)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">Array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">))</span>

    <span class="c">#### Hyperparameters</span>

    <span class="c"># beta[:] are the parameters of the Dirichlet prior over pi[:]</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">Array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,))</span>

    <span class="c"># alpha[k,:] are the parameters of the Dirichlet prior over theta[j,k,:]</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">Array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">))</span>


    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">,</span> <span class="n">nannotators</span><span class="p">,</span>
                 <span class="n">pi</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span>
                 <span class="n">alpha</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">traits</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create an instance of ModelB.</span>

<span class="sd">        Arguments</span>
<span class="sd">        ----------</span>
<span class="sd">        nclasses : int</span>
<span class="sd">            Number of possible annotation classes</span>

<span class="sd">        nannotators : int</span>
<span class="sd">            Number of annotators</span>

<span class="sd">        pi : ndarray, shape = (n_classes,)</span>
<span class="sd">            pi[k] is the prior probability of class k.</span>

<span class="sd">        theta : ndarray, shape = (n_annotators, n_classes, n_classes)</span>
<span class="sd">            theta[j,k,k&#39;] is the probability of annotator j reporting class k&#39;,</span>
<span class="sd">            while the true label is k.</span>

<span class="sd">        alpha : ndarray, shape = (n_classes, n_classes)</span>
<span class="sd">            Parameters of Dirichlet prior over annotator choices</span>
<span class="sd">            Default: peaks at correct annotation, decays to 1</span>

<span class="sd">        beta : ndarray</span>
<span class="sd">            Parameters of Dirichlet prior over model categories</span>
<span class="sd">            Default: beta[i] = 2.0</span>
<span class="sd">         &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nclasses</span> <span class="o">=</span> <span class="n">nclasses</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nannotators</span> <span class="o">=</span> <span class="n">nannotators</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pi</span> <span class="o">=</span> <span class="n">pi</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>

        <span class="c"># initialize prior parameters if not specified</span>
        <span class="k">if</span> <span class="n">alpha</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_alpha</span><span class="p">(</span><span class="n">nclasses</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">beta</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_beta</span><span class="p">(</span><span class="n">nclasses</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">ModelB</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">traits</span><span class="p">)</span>


    <span class="c">##### Model and data generation methods ###################################</span>

    <span class="nd">@staticmethod</span>
<div class="viewcode-block" id="ModelB.create_initial_state"><a class="viewcode-back" href="../../pyanno.models.html#pyanno.modelB.ModelB.create_initial_state">[docs]</a>    <span class="k">def</span> <span class="nf">create_initial_state</span><span class="p">(</span><span class="n">nclasses</span><span class="p">,</span> <span class="n">nannotators</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Factory method returning a model with random initial parameters.</span>

<span class="sd">        It is often more convenient to use this factory method over the</span>
<span class="sd">        constructor, as one does not need to specify the initial model</span>
<span class="sd">        parameters.</span>

<span class="sd">        The parameters theta and pi, controlling accuracy and prevalence,</span>
<span class="sd">        are initialized at random from the prior alpha and beta:</span>

<span class="sd">        :math:`\\theta_j^k \sim \mathrm{Dirichlet}(\mathbf{\\alpha_k})`</span>

<span class="sd">        :math:`\pi \sim \mathrm{Dirichlet}(\mathbf{\\beta})`</span>

<span class="sd">        If not defined, the prior parameters alpha ad beta are defined as</span>
<span class="sd">        described below.</span>

<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        nclasses : int</span>
<span class="sd">            Number of label classes</span>

<span class="sd">        nannotators : int</span>
<span class="sd">            Number of annotators</span>

<span class="sd">        alpha : ndarray</span>
<span class="sd">            Parameters of Dirichlet prior over annotator choices</span>
<span class="sd">            Default value is a band matrix that peaks at the correct</span>
<span class="sd">            annotation, with a value of 16 and decays to 1 with diverging</span>
<span class="sd">            classes. This prior is ideal for ordinal annotations.</span>

<span class="sd">        beta : ndarray</span>
<span class="sd">            Parameters of Dirichlet prior over model categories</span>
<span class="sd">            Default value for beta[i] is 1.0 .</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        model : :class:`~ModelB`</span>
<span class="sd">            Instance of ModelB</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># NOTE: this is Bob Carpenter&#39;s prior; it is a *very* strong prior</span>
        <span class="c"># over alpha for ordinal data, and becomes stronger for larger number</span>
        <span class="c"># of classes. What is a sensible prior?</span>
<span class="c">#        if alpha is None:</span>
<span class="c">#            alpha = np.empty((nclasses, nclasses))</span>
<span class="c">#            for k1 in xrange(nclasses):</span>
<span class="c">#                for k2 in xrange(nclasses):</span>
<span class="c">#                    # using Bob Carpenter&#39;s choice as a prior</span>
<span class="c">#                    alpha[k1,k2] = max(1, (nclasses + (0.5 if k1 == k2 else 0)</span>
<span class="c">#                                           - abs(k1 - k2)) ** 4)</span>
<span class="c">#</span>
<span class="c">#        if beta is None:</span>
<span class="c">#            beta = 2.*np.ones(shape=(nclasses,))</span>

        <span class="k">if</span> <span class="n">alpha</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">ModelB</span><span class="o">.</span><span class="n">default_alpha</span><span class="p">(</span><span class="n">nclasses</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">beta</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="n">ModelB</span><span class="o">.</span><span class="n">default_beta</span><span class="p">(</span><span class="n">nclasses</span><span class="p">)</span>

        <span class="c"># generate random distributions of prevalence and accuracy</span>
        <span class="n">pi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">dirichlet</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">ModelB</span><span class="o">.</span><span class="n">_random_theta</span><span class="p">(</span><span class="n">nclasses</span><span class="p">,</span> <span class="n">nannotators</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ModelB</span><span class="p">(</span><span class="n">nclasses</span><span class="p">,</span> <span class="n">nannotators</span><span class="p">,</span> <span class="n">pi</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>

</div>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_random_theta</span><span class="p">(</span><span class="n">nclasses</span><span class="p">,</span> <span class="n">nannotators</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nannotators</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">nannotators</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">nclasses</span><span class="p">):</span>
                <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">dirichlet</span><span class="p">(</span><span class="n">alpha</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:])</span>
        <span class="k">return</span> <span class="n">theta</span>


    <span class="nd">@staticmethod</span>
<div class="viewcode-block" id="ModelB.default_beta"><a class="viewcode-back" href="../../pyanno.models.html#pyanno.modelB.ModelB.default_beta">[docs]</a>    <span class="k">def</span> <span class="nf">default_beta</span><span class="p">(</span><span class="n">nclasses</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">nclasses</span><span class="p">,))</span>

</div>
    <span class="nd">@staticmethod</span>
<div class="viewcode-block" id="ModelB.default_alpha"><a class="viewcode-back" href="../../pyanno.models.html#pyanno.modelB.ModelB.default_alpha">[docs]</a>    <span class="k">def</span> <span class="nf">default_alpha</span><span class="p">(</span><span class="n">nclasses</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">create_band_matrix</span><span class="p">(</span><span class="n">nclasses</span><span class="p">,</span> <span class="n">ALPHA_DEFAULT</span><span class="p">)</span>

</div>
<div class="viewcode-block" id="ModelB.generate_labels"><a class="viewcode-back" href="../../pyanno.models.html#pyanno.modelB.ModelB.generate_labels">[docs]</a>    <span class="k">def</span> <span class="nf">generate_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nitems</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate random labels from the model.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">random_categorical</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">nitems</span><span class="p">)</span>

</div>
<div class="viewcode-block" id="ModelB.generate_annotations_from_labels"><a class="viewcode-back" href="../../pyanno.models.html#pyanno.modelB.ModelB.generate_annotations_from_labels">[docs]</a>    <span class="k">def</span> <span class="nf">generate_annotations_from_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate random annotations from the model, given labels</span>

<span class="sd">        The method samples random annotations from the conditional probability</span>
<span class="sd">        distribution of annotations, :math:`x_i^j`</span>
<span class="sd">        given labels, :math:`y_i`:</span>

<span class="sd">        :math:`x_i^j \sim \mathrm{Categorical}(\mathbf{\\theta_j^{y_i}})`</span>

<span class="sd">        Arguments</span>
<span class="sd">        ----------</span>
<span class="sd">        labels : ndarray, shape = (n_items,), dtype = int</span>
<span class="sd">            Set of &quot;true&quot; labels</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        annotations : ndarray, shape = (n_items, n_annotators)</span>
<span class="sd">            annotations[i,j] is the annotation of annotator j for item i</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nitems</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">annotations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nitems</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nannotators</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nannotators</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">nitems</span><span class="p">):</span>
                <span class="n">annotations</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>  <span class="o">=</span> <span class="p">(</span>
                    <span class="n">random_categorical</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">],:],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">annotations</span>

</div>
<div class="viewcode-block" id="ModelB.generate_annotations"><a class="viewcode-back" href="../../pyanno.models.html#pyanno.modelB.ModelB.generate_annotations">[docs]</a>    <span class="k">def</span> <span class="nf">generate_annotations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nitems</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate a random annotation set from the model.</span>

<span class="sd">        Sample a random set of annotations from the probability distribution</span>
<span class="sd">        defined the current model parameters:</span>

<span class="sd">            1) Label classes are generated from the prior distribution, pi</span>

<span class="sd">            2) Annotations are generated from the conditional distribution of</span>
<span class="sd">               annotations given classes, theta</span>

<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        nitems : int</span>
<span class="sd">            Number of items to sample</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        annotations : ndarray, shape = (n_items, n_annotators)</span>
<span class="sd">            annotations[i,j] is the annotation of annotator j for item i</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_labels</span><span class="p">(</span><span class="n">nitems</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_annotations_from_labels</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>


    <span class="c">##### Parameters estimation methods #######################################</span>

    <span class="c"># TODO start from sample frequencies</span></div>
<div class="viewcode-block" id="ModelB.map"><a class="viewcode-back" href="../../pyanno.models.html#pyanno.modelB.ModelB.map">[docs]</a>    <span class="k">def</span> <span class="nf">map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">annotations</span><span class="p">,</span>
            <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.00001</span><span class="p">,</span> <span class="n">init_accuracy</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes maximum a posteriori (MAP) estimation of parameters.</span>

<span class="sd">        Estimate the parameters :attr:`theta` and :attr:`pi` from a set of</span>
<span class="sd">        observed annotations using maximum a posteriori estimation.</span>

<span class="sd">        Arguments</span>
<span class="sd">        ----------</span>
<span class="sd">        annotations : ndarray, shape = (n_items, n_annotators)</span>
<span class="sd">            annotations[i,j] is the annotation of annotator j for item i</span>

<span class="sd">        epsilon : float</span>
<span class="sd">            The estimation is interrupted when the objective function has</span>
<span class="sd">            changed less than `epsilon` on average over the last 10 iterations</span>

<span class="sd">        initial_accuracy : float</span>
<span class="sd">            Initialize the accuracy parameters, `theta` to a set of</span>
<span class="sd">            distributions where theta[j,k,k&#39;] = initial_accuracy if k==k&#39;,</span>
<span class="sd">            and (1-initial_accuracy) / (n_classes - 1)</span>

<span class="sd">        max_epoch : int</span>
<span class="sd">            Interrupt the estimation after `max_epoch` iterations</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_raise_if_incompatible</span><span class="p">(</span><span class="n">annotations</span><span class="p">)</span>

        <span class="n">map_em_generator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_em_step</span><span class="p">(</span><span class="n">annotations</span><span class="p">,</span> <span class="n">init_accuracy</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_parameter_estimation</span><span class="p">(</span><span class="n">map_em_generator</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">)</span>

</div>
<div class="viewcode-block" id="ModelB.mle"><a class="viewcode-back" href="../../pyanno.models.html#pyanno.modelB.ModelB.mle">[docs]</a>    <span class="k">def</span> <span class="nf">mle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">annotations</span><span class="p">,</span>
            <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">init_accuracy</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes maximum likelihood estimate (MLE) of parameters.</span>

<span class="sd">        Estimate the parameters :attr:`theta` and :attr:`pi` from a set of</span>
<span class="sd">        observed annotations using maximum likelihood estimation.</span>

<span class="sd">        Arguments</span>
<span class="sd">        ----------</span>
<span class="sd">        annotations : ndarray, shape = (n_items, n_annotators)</span>
<span class="sd">            annotations[i,j] is the annotation of annotator j for item i</span>

<span class="sd">        epsilon : float</span>
<span class="sd">            The estimation is interrupted when the objective function has</span>
<span class="sd">            changed less than `epsilon` on average over the last 10 iterations</span>

<span class="sd">        initial_accuracy : float</span>
<span class="sd">            Initialize the accuracy parameters, `theta` to a set of</span>
<span class="sd">            distributions where theta[j,k,k&#39;] = initial_accuracy if k==k&#39;,</span>
<span class="sd">            and (1-initial_accuracy) / (n_classes - 1)</span>

<span class="sd">        max_epoch : int</span>
<span class="sd">            Interrupt the estimation after `max_epoch` iterations</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_raise_if_incompatible</span><span class="p">(</span><span class="n">annotations</span><span class="p">)</span>

        <span class="n">mle_em_generator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mle_em_step</span><span class="p">(</span><span class="n">annotations</span><span class="p">,</span> <span class="n">init_accuracy</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_parameter_estimation</span><span class="p">(</span><span class="n">mle_em_generator</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">)</span>

</div>
    <span class="k">def</span> <span class="nf">_parameter_estimation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_iterator</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">):</span>

        <span class="k">if</span> <span class="n">epsilon</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">:</span> <span class="k">raise</span> <span class="n">PyannoValueError</span><span class="p">(</span><span class="s">&quot;epsilon &lt; 0.0&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_epochs</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="n">PyannoValueError</span><span class="p">(</span><span class="s">&quot;max_epochs &lt; 0&quot;</span><span class="p">)</span>

        <span class="n">info_str</span> <span class="o">=</span> <span class="s">&quot;Epoch={0:6d}  obj={1:+10.4f}   diff={2:10.4f}&quot;</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">&#39;Start parameters optimization...&#39;</span><span class="p">)</span>

        <span class="n">epoch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">obj_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">for</span> <span class="n">objective</span><span class="p">,</span> <span class="n">prev_est</span><span class="p">,</span> <span class="n">cat_est</span><span class="p">,</span> <span class="n">acc_est</span> <span class="ow">in</span> <span class="n">learning_iterator</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">info_str</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">objective</span><span class="p">,</span> <span class="n">diff</span><span class="p">))</span>

            <span class="n">obj_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">objective</span><span class="p">)</span>

            <span class="c"># stopping conditions</span>
            <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="n">max_epochs</span><span class="p">:</span> <span class="k">break</span>
            <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>
                <span class="n">diff</span> <span class="o">=</span> <span class="p">(</span><span class="n">obj_history</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">-</span> <span class="n">obj_history</span><span class="p">[</span><span class="n">epoch</span><span class="o">-</span><span class="mi">10</span><span class="p">])</span> <span class="o">/</span> <span class="mf">10.0</span>
                <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span> <span class="k">break</span>

            <span class="n">epoch</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">&#39;Parameters optimization finished&#39;</span><span class="p">)</span>

        <span class="c"># update internal parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pi</span> <span class="o">=</span> <span class="n">prev_est</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">acc_est</span>

        <span class="k">return</span> <span class="n">cat_est</span>


    <span class="k">def</span> <span class="nf">_map_em_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">annotations</span><span class="p">,</span> <span class="n">init_accuracy</span><span class="o">=</span><span class="mf">0.6</span><span class="p">):</span>
       <span class="c"># TODO move argument checking to traits</span>
<span class="c">#        if not np.all(beta &gt; 0.):</span>
<span class="c">#            raise ValueError(&quot;beta should be larger than 0&quot;)</span>
<span class="c">#        if not np.all(alpha &gt; 0.):</span>
<span class="c">#            raise ValueError(&quot;alpha should be larger than 0&quot;)</span>
<span class="c">#</span>
<span class="c">#        if annotations.shape != (nitems, nannotators):</span>
<span class="c">#            raise ValueError(&quot;size of `annotations` should be nitems x nannotators&quot;)</span>
<span class="c">#        if init_accuracy &lt; 0.0 or init_accuracy &gt; 1.0:</span>
<span class="c">#            raise ValueError(&quot;init_accuracy not in [0,1]&quot;)</span>
<span class="c">#        if len(alpha) != nclasses:</span>
<span class="c">#            raise ValueError(&quot;len(alpha) != K&quot;)</span>
<span class="c">#        for k in xrange(nclasses):</span>
<span class="c">#            if len(alpha[k]) != nclasses:</span>
<span class="c">#                raise ValueError(&quot;len(alpha[k]) != K&quot;)</span>
<span class="c">#        if len(beta) != nclasses:</span>
<span class="c">#            raise ValueError(&quot;len(beta) != K&quot;)</span>

        <span class="c"># True if annotations is missing</span>
        <span class="n">missing_mask_nclasses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_missing_mask</span><span class="p">(</span><span class="n">annotations</span><span class="p">)</span>

        <span class="c"># prevalence is P( category )</span>
        <span class="n">prevalence</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_prevalence</span><span class="p">()</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_accuracy</span><span class="p">(</span><span class="n">init_accuracy</span><span class="p">)</span>

        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="c"># Expectation step (E-step)</span>
            <span class="c"># compute marginal likelihood P(category[i] | model, data)</span>

            <span class="n">log_likelihood</span><span class="p">,</span> <span class="n">unnorm_category</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood_core</span><span class="p">(</span><span class="n">annotations</span><span class="p">,</span>
                                          <span class="n">prevalence</span><span class="p">,</span>
                                          <span class="n">accuracy</span><span class="p">,</span>
                                          <span class="n">missing_mask_nclasses</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">log_prior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_prior</span><span class="p">(</span><span class="n">prevalence</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>

            <span class="c"># category is P(category[i] = k | model, data)</span>
            <span class="n">category</span> <span class="o">=</span> <span class="n">unnorm_category</span> <span class="o">/</span> <span class="n">unnorm_category</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)[:,</span><span class="bp">None</span><span class="p">]</span>

            <span class="c"># return here with E[cat|prev,acc] and LL(prev,acc;y)</span>
            <span class="k">yield</span> <span class="p">(</span><span class="n">log_prior</span><span class="o">+</span><span class="n">log_likelihood</span><span class="p">,</span> <span class="n">prevalence</span><span class="p">,</span> <span class="n">category</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>

            <span class="c"># Maximization step (M-step)</span>
            <span class="c"># update parameters to maximize likelihood</span>
            <span class="n">prevalence</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_prevalence</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_accuracy</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">annotations</span><span class="p">,</span>
                                              <span class="n">use_prior</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">_mle_em_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">annotations</span><span class="p">,</span> <span class="n">init_accuracy</span><span class="o">=</span><span class="mf">0.6</span><span class="p">):</span>
        <span class="c"># True if annotations is missing</span>
        <span class="n">missing_mask_nclasses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_missing_mask</span><span class="p">(</span><span class="n">annotations</span><span class="p">)</span>

        <span class="c"># prevalence is P( category )</span>
        <span class="n">prevalence</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">nclasses</span><span class="p">,))</span>
        <span class="n">prevalence</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nclasses</span><span class="p">))</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_accuracy</span><span class="p">(</span><span class="n">init_accuracy</span><span class="p">)</span>

        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="c"># Expectation step (E-step)</span>
            <span class="c"># compute marginal likelihood P(category[i] | model, data)</span>

            <span class="n">log_likelihood</span><span class="p">,</span> <span class="n">unnorm_category</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood_core</span><span class="p">(</span><span class="n">annotations</span><span class="p">,</span>
                                          <span class="n">prevalence</span><span class="p">,</span>
                                          <span class="n">accuracy</span><span class="p">,</span>
                                          <span class="n">missing_mask_nclasses</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c"># category is P(category[i] = k | model, data)</span>
            <span class="n">category</span> <span class="o">=</span> <span class="n">unnorm_category</span> <span class="o">/</span> <span class="n">unnorm_category</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)[:,</span><span class="bp">None</span><span class="p">]</span>

            <span class="c"># return here with E[cat|prev,acc] and LL(prev,acc;y)</span>
            <span class="k">yield</span> <span class="p">(</span><span class="n">log_likelihood</span><span class="p">,</span> <span class="n">prevalence</span><span class="p">,</span> <span class="n">category</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>

            <span class="c"># Maximization step (M-step)</span>
            <span class="c"># update parameters to maximize likelihood</span>
            <span class="n">prevalence</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">category</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_accuracy</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">annotations</span><span class="p">,</span>
                                              <span class="n">use_prior</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">_compute_prevalence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return prevalence, P( category ).&quot;&quot;&quot;</span>
        <span class="n">beta_prior_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">-</span> <span class="mf">1.</span>
        <span class="k">if</span> <span class="n">category</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="c"># initialize at the *mode* of the distribution</span>
            <span class="k">return</span> <span class="n">normalize</span><span class="p">(</span><span class="n">beta_prior_count</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">normalize</span><span class="p">(</span><span class="n">beta_prior_count</span> <span class="o">+</span> <span class="n">category</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>


    <span class="k">def</span> <span class="nf">_initial_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_accuracy</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return initial setting for accuracy.&quot;&quot;&quot;</span>
        <span class="n">nannotators</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nannotators</span>
        <span class="n">nclasses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nclasses</span>

        <span class="c"># accuracy[j,k,k&#39;] is P(annotation_j = k&#39; | category=k)</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nannotators</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">))</span>
        <span class="n">accuracy</span><span class="o">.</span><span class="n">fill</span><span class="p">((</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">init_accuracy</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">nclasses</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">nclasses</span><span class="p">):</span>
            <span class="n">accuracy</span><span class="p">[:,</span> <span class="n">k</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">init_accuracy</span>
        <span class="k">return</span> <span class="n">accuracy</span>


    <span class="k">def</span> <span class="nf">_compute_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">category</span><span class="p">,</span> <span class="n">annotations</span><span class="p">,</span> <span class="n">use_prior</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return accuracy, P(annotation_j = k&#39; | category=k)</span>

<span class="sd">        Helper function to compute an estimate of the accuracy parameters</span>
<span class="sd">        theta, given labels and annotations.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        accuracy : ndarray, shape = (n_annotators, n_classes, n_classes)</span>
<span class="sd">            accuracy[j,k,k&#39;] = P(annotation_j = k&#39; | category=k).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nitems</span><span class="p">,</span> <span class="n">nannotators</span> <span class="o">=</span> <span class="n">annotations</span><span class="o">.</span><span class="n">shape</span>
        <span class="c"># alpha - 1 : the mode of a Dirichlet is  (alpha_i - 1) / (alpha_0 - K)</span>
        <span class="n">alpha_prior_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">-</span> <span class="mf">1.</span>
        <span class="n">valid_mask</span> <span class="o">=</span> <span class="n">is_valid</span><span class="p">(</span><span class="n">annotations</span><span class="p">)</span>

        <span class="n">annotators</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nannotators</span><span class="p">)[</span><span class="bp">None</span><span class="p">,:]</span>
        <span class="k">if</span> <span class="n">use_prior</span><span class="p">:</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">alpha_prior_count</span><span class="p">,</span> <span class="p">(</span><span class="n">nannotators</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nannotators</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nclasses</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nclasses</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">nitems</span><span class="p">):</span>
            <span class="n">valid</span> <span class="o">=</span> <span class="n">valid_mask</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span>
            <span class="n">accuracy</span><span class="p">[</span><span class="n">annotators</span><span class="p">[:,</span><span class="n">valid</span><span class="p">],:,</span><span class="n">annotations</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">valid</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">category</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span>
        <span class="n">accuracy</span> <span class="o">/=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">2</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="bp">None</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">accuracy</span>


    <span class="k">def</span> <span class="nf">_compute_category</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">annotations</span><span class="p">,</span> <span class="n">prevalence</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span>
                          <span class="n">missing_mask_nclasses</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute P(category[i] = k | model, annotations).</span>

<span class="sd">        Arguments</span>
<span class="sd">        ----------</span>
<span class="sd">        annotations : ndarray</span>
<span class="sd">            Array of annotations</span>

<span class="sd">        prevalence : ndarray</span>
<span class="sd">            Gamma parameters</span>

<span class="sd">        accuracy : ndarray</span>
<span class="sd">            Theta parameters</span>

<span class="sd">        missing_mask_nclasses : ndarray, shape=(nitems, nannotators, n_classes)</span>
<span class="sd">            Mask with True at missing values, tiled in the third dimension.</span>
<span class="sd">            If None, it is computed, but it can be specified to speed-up</span>
<span class="sd">            computations.</span>

<span class="sd">        normalize : bool</span>
<span class="sd">            If False, do not normalize the distribution.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        category : ndarray, shape = (n_items, n_classes)</span>
<span class="sd">            category[i,k] is the (unnormalized) probability of class k for</span>
<span class="sd">            item i</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">nitems</span><span class="p">,</span> <span class="n">nannotators</span> <span class="o">=</span> <span class="n">annotations</span><span class="o">.</span><span class="n">shape</span>

        <span class="c"># compute mask of invalid entries in annotations if necessary</span>
        <span class="k">if</span> <span class="n">missing_mask_nclasses</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">missing_mask_nclasses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_missing_mask</span><span class="p">(</span><span class="n">annotations</span><span class="p">)</span>

        <span class="c"># unnorm_category is P(category[i] = k | model, data), unnormalized</span>
        <span class="n">unnorm_category</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">prevalence</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="p">(</span><span class="n">nitems</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="c"># mask missing annotations</span>
        <span class="n">annotators</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nannotators</span><span class="p">)[</span><span class="bp">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">masked_array</span><span class="p">(</span><span class="n">accuracy</span><span class="p">[</span><span class="n">annotators</span><span class="p">,</span> <span class="p">:,</span> <span class="n">annotations</span><span class="p">],</span>
                                 <span class="n">mask</span><span class="o">=</span><span class="n">missing_mask_nclasses</span><span class="p">)</span>
        <span class="n">unnorm_category</span> <span class="o">*=</span> <span class="n">tmp</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">unnorm_category</span> <span class="o">/</span> <span class="n">unnorm_category</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)[:,</span><span class="bp">None</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">unnorm_category</span>


    <span class="k">def</span> <span class="nf">_missing_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">annotations</span><span class="p">):</span>
        <span class="n">missing_mask</span> <span class="o">=</span> <span class="o">~</span> <span class="n">is_valid</span><span class="p">(</span><span class="n">annotations</span><span class="p">)</span>
        <span class="n">missing_mask_nclasses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">missing_mask</span><span class="p">[:,</span> <span class="p">:,</span> <span class="bp">None</span><span class="p">],</span>
            <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nclasses</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">missing_mask_nclasses</span>


    <span class="c">##### Model likelihood methods ############################################</span>

<div class="viewcode-block" id="ModelB.log_likelihood"><a class="viewcode-back" href="../../pyanno.models.html#pyanno.modelB.ModelB.log_likelihood">[docs]</a>    <span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">annotations</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the log likelihood of a set of annotations given the model.</span>

<span class="sd">        Returns log P(annotations | current model parameters).</span>

<span class="sd">        Arguments</span>
<span class="sd">        ----------</span>
<span class="sd">        annotations : ndarray, shape = (n_items, n_annotators)</span>
<span class="sd">            annotations[i,j] is the annotation of annotator j for item i</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        log_lhood : float</span>
<span class="sd">            log likelihood of `annotations`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_raise_if_incompatible</span><span class="p">(</span><span class="n">annotations</span><span class="p">)</span>

        <span class="n">missing_mask_nclasses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_missing_mask</span><span class="p">(</span><span class="n">annotations</span><span class="p">)</span>
        <span class="n">llhood</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood_core</span><span class="p">(</span><span class="n">annotations</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span>
                                              <span class="n">missing_mask_nclasses</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">llhood</span>

</div>
    <span class="k">def</span> <span class="nf">_log_likelihood_core</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">annotations</span><span class="p">,</span>
                             <span class="n">prevalence</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span>
                             <span class="n">missing_mask_nclasses</span><span class="p">):</span>

        <span class="n">unnorm_category</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_category</span><span class="p">(</span><span class="n">annotations</span><span class="p">,</span>
                                                 <span class="n">prevalence</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span>
                                                 <span class="n">missing_mask_nclasses</span><span class="p">,</span>
                                                 <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

        <span class="n">llhood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">unnorm_category</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">llhood</span><span class="p">):</span>
            <span class="n">llhood</span> <span class="o">=</span> <span class="n">SMALLEST_FLOAT</span>

        <span class="k">return</span> <span class="n">llhood</span><span class="p">,</span> <span class="n">unnorm_category</span>


    <span class="k">def</span> <span class="nf">_log_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prevalence</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">):</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
        <span class="n">log_prior</span> <span class="o">=</span> <span class="n">dirichlet_llhood</span><span class="p">(</span><span class="n">prevalence</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nannotators</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nclasses</span><span class="p">):</span>
                <span class="n">log_prior</span> <span class="o">+=</span> <span class="n">dirichlet_llhood</span><span class="p">(</span><span class="n">accuracy</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">k</span><span class="p">,:],</span> <span class="n">alpha</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">log_prior</span>


    <span class="c">##### Sampling posterior over parameters ##################################</span>

<div class="viewcode-block" id="ModelB.sample_posterior_over_accuracy"><a class="viewcode-back" href="../../pyanno.models.html#pyanno.modelB.ModelB.sample_posterior_over_accuracy">[docs]</a>    <span class="k">def</span> <span class="nf">sample_posterior_over_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">annotations</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">,</span>
                                       <span class="n">burn_in_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                       <span class="n">thin_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                       <span class="n">return_all_samples</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return samples from posterior distribution over theta given data.</span>

<span class="sd">        Samples are drawn using Gibbs sampling, i.e., alternating between</span>
<span class="sd">        sampling from the conditional distribution of theta given the</span>
<span class="sd">        annotations and the label classes, and sampling from the conditional</span>
<span class="sd">        distribution of the classes given theta and the annotations.</span>

<span class="sd">        This results in a fast-mixing sampler, and so the parameters</span>
<span class="sd">        controlling burn-in and thinning can be set to a small number</span>
<span class="sd">        of samples.</span>

<span class="sd">        Arguments</span>
<span class="sd">        ----------</span>
<span class="sd">        annotations : ndarray, shape = (n_items, n_annotators)</span>
<span class="sd">            annotations[i,j] is the annotation of annotator j for item i</span>

<span class="sd">        nsamples : int</span>
<span class="sd">            number of samples to draw from the posterior</span>

<span class="sd">        burn_in_samples : int</span>
<span class="sd">            Discard the first `burn_in_samples` during the initial burn-in</span>
<span class="sd">            phase, where the Monte Carlo chain converges to the posterior</span>

<span class="sd">        thin_samples : int</span>
<span class="sd">            Only return one every `thin_samples` samples in order to reduce</span>
<span class="sd">            the auto-correlation in the sampling chain. This is called</span>
<span class="sd">            &quot;thinning&quot; in MCMC parlance.</span>

<span class="sd">        return_all_samples : bool</span>
<span class="sd">            If True, return not only samples for the parameters theta,</span>
<span class="sd">            but also for the parameters pi, and the label classes, y.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        samples : ndarray, shape = (n_samples, n_annotators, nclasses, nclasses)</span>
<span class="sd">            samples[i,...] is one sample from the posterior distribution over</span>
<span class="sd">            the parameters `theta`</span>

<span class="sd">        (theta, pi, labels) : tuple of ndarray</span>
<span class="sd">            If the keyword argument `return_all_samples` is set to True,</span>
<span class="sd">            return a tuple with the samples for the parameters theta,</span>
<span class="sd">            the parameters pi, and the label classes, y</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_raise_if_incompatible</span><span class="p">(</span><span class="n">annotations</span><span class="p">)</span>
        <span class="n">nsamples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_total_nsamples</span><span class="p">(</span><span class="n">nsamples</span><span class="p">,</span>
                                                <span class="n">burn_in_samples</span><span class="p">,</span>
                                                <span class="n">thin_samples</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">&#39;Start collecting samples...&#39;</span><span class="p">)</span>

        <span class="c"># use Gibbs sampling</span>
        <span class="n">nitems</span><span class="p">,</span> <span class="n">nannotators</span> <span class="o">=</span> <span class="n">annotations</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">nclasses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nclasses</span>
        <span class="n">alpha_prior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
        <span class="n">beta_prior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span>

        <span class="c"># arrays holding the current samples</span>
        <span class="n">theta_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">nannotators</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">return_all_samples</span><span class="p">:</span>
            <span class="n">pi_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">nclasses</span><span class="p">))</span>
            <span class="n">label_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">nitems</span><span class="p">))</span>

        <span class="n">theta_curr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">pi_curr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">label_curr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nitems</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">sidx</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">nsamples</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">((</span><span class="n">sidx</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">50</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">&#39;... collected {} samples&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sidx</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>

            <span class="c">####### A: sample labels given annotations, theta and pi</span>

            <span class="c">### compute posterior over label classes given theta and pi</span>
            <span class="n">category_distr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_category</span><span class="p">(</span><span class="n">annotations</span><span class="p">,</span>
                                                    <span class="n">pi_curr</span><span class="p">,</span>
                                                    <span class="n">theta_curr</span><span class="p">)</span>

            <span class="c">### sample from the categorical distribution over labels</span>
            <span class="c"># 1) precompute cumulative distributions</span>
            <span class="n">cum_distr</span> <span class="o">=</span> <span class="n">category_distr</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

            <span class="c"># 2) precompute random values</span>
            <span class="n">rand</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">nitems</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">nitems</span><span class="p">):</span>
                <span class="c"># 3) samples from i-th categorical distribution</span>
                <span class="n">label_curr</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">cum_distr</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">rand</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

            <span class="c">####### B: sample theta given annotations and label classes</span>

            <span class="c"># 1) compute alpha parameters of Dirichlet posterior</span>
            <span class="n">alpha_post</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">alpha_prior</span><span class="p">,</span> <span class="p">(</span><span class="n">nannotators</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nannotators</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nclasses</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nclasses</span><span class="p">):</span>
                        <span class="n">alpha_post</span><span class="p">[</span><span class="n">l</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="p">((</span><span class="n">label_curr</span><span class="o">==</span><span class="n">k</span><span class="p">)</span>
                                              <span class="o">&amp;</span> <span class="p">(</span><span class="n">annotations</span><span class="p">[:,</span><span class="n">l</span><span class="p">]</span><span class="o">==</span><span class="n">i</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="c"># 2) sample thetas</span>
            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nannotators</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nclasses</span><span class="p">):</span>
                    <span class="n">theta_curr</span><span class="p">[</span><span class="n">l</span><span class="p">,</span><span class="n">k</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">dirichlet</span><span class="p">(</span><span class="n">alpha_post</span><span class="p">[</span><span class="n">l</span><span class="p">,</span><span class="n">k</span><span class="p">,:])</span>

            <span class="c">####### C: sample pi given label classes</span>

            <span class="c"># 1) compute beta parameters of dirichlet posterior</span>
            <span class="c"># number of labels of class k</span>
            <span class="n">count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">label_curr</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="n">nclasses</span><span class="p">)</span>
            <span class="n">beta_hat</span> <span class="o">=</span> <span class="n">beta_prior</span> <span class="o">+</span> <span class="n">count</span>
            <span class="n">pi_curr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">dirichlet</span><span class="p">(</span><span class="n">beta_hat</span><span class="p">)</span>

            <span class="c"># copy current samples</span>
            <span class="n">theta_samples</span><span class="p">[</span><span class="n">sidx</span><span class="p">,</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta_curr</span>
            <span class="k">if</span> <span class="n">return_all_samples</span><span class="p">:</span>
                <span class="n">pi_samples</span><span class="p">[</span><span class="n">sidx</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">pi_curr</span>
                <span class="n">label_samples</span><span class="p">[</span><span class="n">sidx</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">label_curr</span>

        <span class="n">theta_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_process_samples</span><span class="p">(</span><span class="n">theta_samples</span><span class="p">,</span>
                                                   <span class="n">burn_in_samples</span><span class="p">,</span>
                                                   <span class="n">thin_samples</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_all_samples</span><span class="p">:</span>
            <span class="n">pi_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_process_samples</span><span class="p">(</span><span class="n">pi_samples</span><span class="p">,</span>
                                                    <span class="n">burn_in_samples</span><span class="p">,</span>
                                                    <span class="n">thin_samples</span><span class="p">)</span>
            <span class="n">label_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_process_samples</span><span class="p">(</span><span class="n">label_samples</span><span class="p">,</span>
                                                       <span class="n">burn_in_samples</span><span class="p">,</span>
                                                       <span class="n">thin_samples</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">theta_samples</span><span class="p">,</span> <span class="n">pi_samples</span><span class="p">,</span> <span class="n">label_samples</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">theta_samples</span>


    <span class="c">##### Posterior distributions #############################################</span>
</div>
<div class="viewcode-block" id="ModelB.infer_labels"><a class="viewcode-back" href="../../pyanno.models.html#pyanno.modelB.ModelB.infer_labels">[docs]</a>    <span class="k">def</span> <span class="nf">infer_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">annotations</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Infer posterior distribution over label classes.</span>

<span class="sd">        Compute the posterior distribution over label classes given observed</span>
<span class="sd">        annotations, :math:`P( \mathbf{y} | \mathbf{x}, \\theta, \omega)`.</span>

<span class="sd">        Arguments</span>
<span class="sd">        ----------</span>
<span class="sd">        annotations : ndarray, shape = (n_items, n_annotators)</span>
<span class="sd">            annotations[i,j] is the annotation of annotator j for item i</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        posterior : ndarray, shape = (n_items, n_classes)</span>
<span class="sd">            posterior[i,k] is the posterior probability of class k given the</span>
<span class="sd">            annotation observed in item i.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_raise_if_incompatible</span><span class="p">(</span><span class="n">annotations</span><span class="p">)</span>

        <span class="n">category</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_category</span><span class="p">(</span><span class="n">annotations</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">category</span>


    <span class="c">##### Compute accuracy ###################################################</span>
</div>
<div class="viewcode-block" id="ModelB.annotator_accuracy"><a class="viewcode-back" href="../../pyanno.models.html#pyanno.modelB.ModelB.annotator_accuracy">[docs]</a>    <span class="k">def</span> <span class="nf">annotator_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the accuracy of each annotator.</span>

<span class="sd">        Compute a summary of the a-priori accuracy of each annotator, i.e.,</span>
<span class="sd">        P( annotator j is correct ). This can be computed from the parameters</span>
<span class="sd">        theta and pi, as</span>

<span class="sd">        P( annotator j is correct )</span>
<span class="sd">        = \sum_k P( annotator j reports k | label is k ) P( label is k )</span>
<span class="sd">        = \sum_k theta[j,k,k] * pi[k]</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        accuracy : ndarray, shape = (n_annotators, )</span>
<span class="sd">            accuracy[j] = P( annotator j is correct )</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">nannotators</span><span class="p">,))</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nclasses</span><span class="p">):</span>
            <span class="n">accuracy</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[:,</span><span class="n">k</span><span class="p">,</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">accuracy</span>

</div>
<div class="viewcode-block" id="ModelB.annotator_accuracy_samples"><a class="viewcode-back" href="../../pyanno.models.html#pyanno.modelB.ModelB.annotator_accuracy_samples">[docs]</a>    <span class="k">def</span> <span class="nf">annotator_accuracy_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta_samples</span><span class="p">,</span> <span class="n">pi_samples</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return samples from the accuracy of each annotator.</span>

<span class="sd">        Given samples from the posterior of accuracy parameters theta</span>
<span class="sd">        (see :method:`sample_posterior_over_accuracy`), compute</span>
<span class="sd">        samples from the posterior distribution of the annotator accuracy,</span>
<span class="sd">        i.e.,</span>

<span class="sd">        P( annotator j is correct | annotations).</span>

<span class="sd">        See also :method:`sample_posterior_over_accuracy`,</span>
<span class="sd">        :method:`annotator_accuracy`</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        accuracy : ndarray, shape = (n_annotators, )</span>
<span class="sd">            accuracy[j] = P( annotator j is correct )</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">nsamples</span> <span class="o">=</span> <span class="n">theta_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nsamples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nannotators</span><span class="p">,))</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nclasses</span><span class="p">):</span>
            <span class="n">accuracy</span> <span class="o">+=</span> <span class="n">theta_samples</span><span class="p">[:,:,</span><span class="n">k</span><span class="p">,</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">pi_samples</span><span class="p">[:,</span><span class="n">k</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">accuracy</span></div></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<h3><a href="../../index.html">Table Of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models.html">pyAnno models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer_guide.html">Developer guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">Library Reference</a></li>
</ul>

<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">pyanno 2.0 documentation</a> &raquo;</li>
          <li><a href="../index.html" >Module code</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011, Pietro Berkes, Bob Carpenter, Andrey Rzhetsky, James A. Evans.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.2.
    </div>
  </body>
</html>